---
layout: post
title: openresty memcached实践
description: 
categories: posts blog
---

最近在做系统的升级改造，准备把两个相似功能的系统合二为一，降低维护两个系统的负担，同时节省机器成本。

### 1.方案设计 

两个系统均为消息队列，不同之处在于A系统采用了http协议的推，B是memcache协议的拉；A系统使用mysql作为存储，B是文件存储。升级的目的是使B系统也支持http协议，从而下线A系统。当时组内讨论有2种方案，一个是在B系统内部支持多协议，一个是采用proxy的模式，让proxy把http转换成memcache发给B。

<!-- more -->
 
如果采用第一种方案，由于A采用的是推的模式，客户端只会发起一个请求，然后由服务端主动推送数据出去，A系统后端存储是mysql，是集中式的，可以实现只发一个请求由前端机将全量的数据推出去。而B是分布式部署，全量的数据分散在不同的机器上，如果只发起一个请求到服务端，那么接收请求的那个节点将会承担将请求分发到其他节点的任务，同时其他节点如何将数据发给客户端也是需要考虑的问题。

如果采用第二种方案，有两种方式实现。一个是用java或者golang写一个支持http转memcache的proxy，一个是利用openresty实现http转换memcache。

在组内的讨论中，首先抛弃了第一种方案，但是在采用第二种方案的哪一种实现方式上有分歧。本人倾向于采用第二种实现方式，原因是openresty本身有memcache模块的支持，还可以做一些负载均衡，容错方面的处理，可以轻松的实现限流，ip禁用等在大流量或者异常情况下的处理。另外，在外部看来没有增加额外的东西，就是前面多了一层nginx，不像前面有个proxy，会给人产生一定的心智负担。

最终采用的是第二种实现方式。

### 2.功能实现

方案实现可以按照客户端http请求从进入nginx到向后端发出memcache请求的流向分为http协议解析，http向memcache协议转换和发起memcache请求三部分。

#### 2.1 http协议解析

lua在nginx中执行会依据一定的执行顺序，本项目中的lua都是在content_by_lua\*阶段执行的。顺便附一张lua在nginx中的执行阶段

![order](/images/nginx_lua/orderOfLuaExec.png)
![explan](/images/nginx_lua/explain.png)

通过`ngx.req.get_uri_args()`可以获取到http请求的uri参数，从得到的参数中找出memcache协议需要的key。由于同一个业务方发送的http请求大都是一样的，由此得到的key值也一样，因此可以将http请求中的uri参数跟对应的key值缓存起来，不必每次都去解析uri参数。使用缓存需要首先在nginx.conf里面配置共享内存的大小，nginx reload操作不会清空共享缓存的内容。

```
lua_shared_dict memcachekey 10m;
```

然后可以通过get/set两个函数分别读写缓存。

```
function getKeyFromCache(key)
    local cache_key = ngx.shared.memcachekey
    local value = cache_key:get(key)
    return value
end

function setKeyToCache(key, value, exptime)
    if not exptime then
        exptime = 0
    end

    local cache_key = ngx.shared.memcachekey
    local succ, err, forcible = cache_key:set(key, value, exptime)
    return err
end
```

#### 2.2 http->memcache协议转换

可以说整个lua脚本做的事情都是协议转换，从拿到http请求的uri参数，到发起memcache请求。重点在发起memcache请求这一步，同时还有些需要注意的点，下面重点说怎样发起memcache请求。

#### 2.3 发起memcache请求

要想使用openresty的memcache模块（该模块默认是编译到发布的openresty的包中，通过nginx -V可以查看），首先需要引入该模块：

```
local memcached = require "resty.memcached"
```

接下来即可使用memcache的get，set方法了,在使用memcache之前需要先创建memcache实例，连接目的端口。

```
local function createMemcache()
    local memc, err = memcached:new()
    if not memc then
        ngx.log(ngx.ERR, "failed to new memcached, cause: ", err)
        return nil
    end
    return memc
end

local function connect(host, port)
    local ok, err = memc:connect(host, port)
    if not ok then
        ngx.log(ngx.ERR, "failed to connect: ", err)
        return err
    end
    return nil
end

```

发起get请求只需要一句`local res, flags, err = memc:get(key)`, err表示这次get请求是否成功，res是返回的数据，flags作为额外信息。

由于消息队列是IO密集型，且服务端输出的是json格式，为了减少服务节点与nginx之间的网络带宽，在服务端增加了对json字符串的gzip压缩，因此需要在nginx增加一个解压缩的过程。将memcache协议中的flagss设置为1表示返回的数据经过了压缩，需要进行解压缩。

我们这里nginx的解压缩使用的是zlib模块，该模块默认没有添加到openresty的发布包中，因此需要添加进去。

安装以及添加zlib到openresty中：

```
$ yum install -y gcc gcc-c++ make automake cmake28
$ git clone https://github.com/brimworks/lua-zlib.git
$ cd lua-zlib
$ cmake -DLUA_INCLUDE_DIR=/data0/openresty/luajit/include/luajit-2.1 -DLUA_LIBRARIES=/data0/openresty/luajit/lib -DUSE_LUAJIT=ON -DUSE_LUA=OFF
$ make && make install
$ cp zlib.so  /usr/local/openresty/lualib/
```

要使用zlib的解压缩也需要首先引入zlib模块：

```
local zlib = require "zlib"
......

if flags == MEMCACHE_COMPRESSED then
    if outputMsg == "" then
        return nil, false
    end
    local stream = zlib.inflate()
    outputMsg = stream(res)
end
```

最后得到的outputMsg即为经过解压缩过后的json串。在使用memcache的过程中，要想复用memcache的连接，只需要一句`local ok, err = memc:set_keepalive(60000, 100)`，前面的参数是保持连接的时间，后面参数是最多保持的连接数。

前面已经说过，B系统是分布式的，要想获取到所有的数据需要向每个后端节点发送memcache请求。后端节点的信息从配置中心获取，然后开启N个协程分别向后端发起请求。

还有一点需要注意的是：因为client只发起一个请求，靠的是服务端推送数据，所以只有服务端主动断开连接，客户端不允许主动断开连接。如果客户端主动断开连接了，nginx需要感知到，不要继续再向后端发起memcache请求了，因为后面的数据，客户端是收不到的。在这里注册一个callback，当客户端关闭连接后，nginx发起的memcache请求即退出。

```
-- register callback cleanup which gets called automatically 
-- when client close the (downstream) connection prematurely
ngx.on_abort(cleanup)

-- cleanup before nginx exit
local function cleanup()
    ngx.log(ngx.ERR, "client close the connection")
    ngx.exit(499)
end
```

![nginx_lua](/images/nginx_lua/nginx_lua.jpg)

### 3.参考

[1] [lua-resty-memcached](https://github.com/openresty/lua-resty-memcached)

[2] [openresty最佳实践](http://www.kancloud.cn/kancloud/openresty-best-practices/50404)
 
[3] [http://www.mrhaoting.com/?p=157](http://www.mrhaoting.com/?p=157)

[4] [http://blog.sina.com.cn/s/blog_6d579ff40100y05x.html](http://blog.sina.com.cn/s/blog_6d579ff40100y05x.html)
